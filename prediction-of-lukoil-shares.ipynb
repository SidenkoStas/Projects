{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv1D, Input\nfrom tensorflow.keras.optimizers import RMSprop \nfrom tensorflow.keras import Model, utils\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nfrom tensorflow.keras.backend import clear_session\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport os\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-21T16:09:52.558586Z","iopub.execute_input":"2022-03-21T16:09:52.55928Z","iopub.status.idle":"2022-03-21T16:09:52.57375Z","shell.execute_reply.started":"2022-03-21T16:09:52.55924Z","shell.execute_reply":"2022-03-21T16:09:52.57222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Load_data():\n    '''\n    Загружаем и соединяем данные.\n    '''\n    \n    l_data1 = pd.read_csv('../input/udt-3-timeseries/18_19.csv', sep=';')\n    l_data2 = pd.read_csv('../input/udt-3-timeseries/16_17.csv', sep=';')\n    xTest = np.load('../input/udt-3-timeseries/x_test.npy')\n    # Объединяем базы из двух файлов.\n    lukoil_data = l_data2.append(l_data1)\n    lukoil_data.drop(columns=['DATE', 'TIME'], axis=1, inplace=True)\n    return lukoil_data, xTest","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:52.576143Z","iopub.execute_input":"2022-03-21T16:09:52.576435Z","iopub.status.idle":"2022-03-21T16:09:52.583412Z","shell.execute_reply.started":"2022-03-21T16:09:52.576393Z","shell.execute_reply":"2022-03-21T16:09:52.582325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Считаем  базу данных.\nlukoil_data, xTest = Load_data() \nlukoil_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:52.585285Z","iopub.execute_input":"2022-03-21T16:09:52.58558Z","iopub.status.idle":"2022-03-21T16:09:53.179696Z","shell.execute_reply.started":"2022-03-21T16:09:52.585538Z","shell.execute_reply":"2022-03-21T16:09:53.178793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Normalization_data(lukoil_data):\n    '''\n    Нормализация данных.\n    '''\n    \n    global xScaler\n    global yScaler\n    global xLen\n    global valLen\n\n    xLen = 300 # Анализируем по xLen прошедшим точкам.\n    valLen = 30000 # Используем valLen записей для проверки.\n    \n    lukoil_data = np.array(lukoil_data)\n    trainLen = lukoil_data.shape[0]-valLen # Размер обучающей выборки.\n     # Делим данные на обучающую и валидационную выборки.\n    xTrain, xTest = lukoil_data[:trainLen], lukoil_data[trainLen+2:]\n    # Масштабируем данные (отдельно для X и Y), чтобы их легче было скормить сетке.\n    xScaler = MinMaxScaler()\n    xScaler.fit(xTrain)\n    xTrain = xScaler.transform(xTrain)\n    xTest = xScaler.transform(xTest)\n    # Сделаем reshape,т.к. у нас только один столбец по одному значению.\n    yTrain = np.reshape(lukoil_data[:trainLen,3],(-1,1))\n    yTest = np.reshape(lukoil_data[trainLen+2:,3],(-1,1)) \n    yScaler = MinMaxScaler()\n    yScaler.fit(yTrain)\n    yTrain = yScaler.transform(yTrain)\n    yTest = yScaler.transform(yTest)\n    print('Данные нормализованы успешно!')\n    return xTrain, xTest, yTrain, yTest","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.181083Z","iopub.execute_input":"2022-03-21T16:09:53.18141Z","iopub.status.idle":"2022-03-21T16:09:53.191616Z","shell.execute_reply.started":"2022-03-21T16:09:53.181371Z","shell.execute_reply":"2022-03-21T16:09:53.190883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Timeseries_data(xyTrain, parametr = 25):\n    '''\n    Метод для выборок с помощью генератора.\n    '''\n    \n    xTrain = xyTrain[0]\n    xTest = xyTrain[1]\n    yTrain = xyTrain[2]\n    yTest = xyTrain[3]\n    \n    # С помощью генератора создаем выборку для обучения.\n    trainDataGen = TimeseriesGenerator(xTrain, yTrain,     # Параметров нашей выборки.\n                                length=xLen, stride=1,     # Для каждой точки (из промежутка длины xLen).\n                                batch_size=parametr)       # Размер batch, который будем подавать для модели.\n    # Аналогичный генератор создадим для валидации при обучении.\n    testDataGen = TimeseriesGenerator(xTest, yTest,\n                                length=xLen, stride=1,\n                                batch_size=parametr)\n    print('Данные успешно сформированы!')\n    return trainDataGen, testDataGen","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.194406Z","iopub.execute_input":"2022-03-21T16:09:53.194701Z","iopub.status.idle":"2022-03-21T16:09:53.203276Z","shell.execute_reply.started":"2022-03-21T16:09:53.194664Z","shell.execute_reply":"2022-03-21T16:09:53.20252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_train_history(history, title): \n    '''\n    Функция отрисовки графиков ошибки.\n    '''\n    \n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(len(loss))\n\n    plt.figure()\n    plt.plot(epochs, loss, 'b', label='Ошибка на этапе обучения.')\n    plt.plot(epochs, val_loss, 'r', label='Ошибка на этапе проверки.')\n    plt.title(title)\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.20465Z","iopub.execute_input":"2022-03-21T16:09:53.205062Z","iopub.status.idle":"2022-03-21T16:09:53.213829Z","shell.execute_reply.started":"2022-03-21T16:09:53.205025Z","shell.execute_reply":"2022-03-21T16:09:53.213157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Нормализуем и создаём генератор для тренировачной и валидационной выборок.\nData_normal = Normalization_data(lukoil_data)\ntrainDataGen, testDataGen = Timeseries_data(Data_normal)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.215305Z","iopub.execute_input":"2022-03-21T16:09:53.215553Z","iopub.status.idle":"2022-03-21T16:09:53.246307Z","shell.execute_reply.started":"2022-03-21T16:09:53.21552Z","shell.execute_reply":"2022-03-21T16:09:53.245433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainDataGen[0][0].shape)\nprint(trainDataGen[0][1].shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.254209Z","iopub.execute_input":"2022-03-21T16:09:53.254903Z","iopub.status.idle":"2022-03-21T16:09:53.262778Z","shell.execute_reply.started":"2022-03-21T16:09:53.254861Z","shell.execute_reply":"2022-03-21T16:09:53.26189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(min_lr=0.000000001, patience=3, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.265501Z","iopub.execute_input":"2022-03-21T16:09:53.265723Z","iopub.status.idle":"2022-03-21T16:09:53.269537Z","shell.execute_reply.started":"2022-03-21T16:09:53.2657Z","shell.execute_reply":"2022-03-21T16:09:53.26878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.270929Z","iopub.execute_input":"2022-03-21T16:09:53.271386Z","iopub.status.idle":"2022-03-21T16:09:53.283445Z","shell.execute_reply.started":"2022-03-21T16:09:53.27135Z","shell.execute_reply":"2022-03-21T16:09:53.282781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создаём модель.\nInputs = Input(shape=(300, 5))\nx = Conv1D(300, 5, input_shape = (xLen,5), activation=\"linear\")(Inputs)\nx = Conv1D(100, 5, input_shape = (xLen,5), activation=\"linear\")(x)\nx = Flatten()(x)\nx = Dense(100, activation=\"relu\")(x)\noutputs = Dense(1)(x)\n\nmodel = Model(inputs=Inputs, outputs=outputs)\nmodel.compile(optimizer=RMSprop(learning_rate=1e-4), loss=\"mse\")\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.285349Z","iopub.execute_input":"2022-03-21T16:09:53.285678Z","iopub.status.idle":"2022-03-21T16:09:53.336018Z","shell.execute_reply.started":"2022-03-21T16:09:53.285626Z","shell.execute_reply":"2022-03-21T16:09:53.334392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Тренируем модель.\nhistory = model.fit(trainDataGen,\n                    epochs=20,\n                    batch_size=25,\n                    validation_data=testDataGen,\n                    callbacks=[reduce_lr],\n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:09:53.337218Z","iopub.execute_input":"2022-03-21T16:09:53.337526Z","iopub.status.idle":"2022-03-21T16:45:09.678718Z","shell.execute_reply.started":"2022-03-21T16:09:53.337491Z","shell.execute_reply":"2022-03-21T16:45:09.677968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_history(history, 'Потери на этапах обучения и проверки модели.')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:45:09.681808Z","iopub.execute_input":"2022-03-21T16:45:09.682134Z","iopub.status.idle":"2022-03-21T16:45:09.898137Z","shell.execute_reply.started":"2022-03-21T16:45:09.682096Z","shell.execute_reply":"2022-03-21T16:45:09.897478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Получим прогноз на тестовой выбоке.\ndef Predict_Model(xTest,currModel):\n    '''\n    Предсказываем ответ сети по тестовой выборке и возвращаем исходные масштаб данных, до нормализации.\n    '''\n    predTest = yScaler.inverse_transform(currModel.predict(xTest[0]))\n    print('Созданы спрогнозированные значения, на части выделенных тестовых данных.')\n    return predTest","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:45:09.899395Z","iopub.execute_input":"2022-03-21T16:45:09.899645Z","iopub.status.idle":"2022-03-21T16:45:09.907116Z","shell.execute_reply.started":"2022-03-21T16:45:09.899611Z","shell.execute_reply":"2022-03-21T16:45:09.906362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_data = Predict_Model(xTest, model) # Прогноз на тестовой выбоке.","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:45:09.908345Z","iopub.execute_input":"2022-03-21T16:45:09.908943Z","iopub.status.idle":"2022-03-21T16:45:12.934585Z","shell.execute_reply.started":"2022-03-21T16:45:09.908837Z","shell.execute_reply":"2022-03-21T16:45:12.933803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Оформление результата.\npredUnscaled = prediction_data.squeeze()\n# Создание датафрейма в нужном формате.\nsubmission = pd.DataFrame({\"Id\":range(1,len(predUnscaled)+1),\"Label\":predUnscaled})\nsubmission.head()\n# Сохранение датафрейма как csv.\nsubmission.to_csv('./SubmissionLukoilPrice.csv', sep=',', index=False, header=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:45:12.936257Z","iopub.execute_input":"2022-03-21T16:45:12.937233Z","iopub.status.idle":"2022-03-21T16:45:13.071728Z","shell.execute_reply.started":"2022-03-21T16:45:12.937189Z","shell.execute_reply":"2022-03-21T16:45:13.070975Z"},"trusted":true},"execution_count":null,"outputs":[]}]}